# 遞迴神經網路與序列模型RNN

[理論講授投影片下載 \(PDF\)](https://drive.google.com/file/d/1tBUn-uCBX7Q1p6yEgGLsRIVnIfn9kJPN/view)

[理論講授 影片播放列表 \(YouTube\)](https://www.youtube.com/playlist?list=PL1f_B9coMEeAGuTBfaAxchSP1_TkM30FS)

[今日課程 投影片下載 \(PDF\)](https://drive.google.com/file/d/1TdFa1WEsnPQKYQcBaJ0omSK8CILsrcL7/view)



Regularization

1. dropout 讓神經網路不要背答案

2. L2 Regularization 讓 weight 不要太大

上面兩個選一個就好



Optimizer

1. momentum 方向的穩定和加速器

2. 可變數的 Learning rete



Adam 使用 momentum + Learning rate 



Batch Normalization

對輸入做 normalization

1. 不會有某個 Feature 太過主導

2. 至少在理論上分析是相對容易的

平均值:0，標準差:1



RestNet

1.神經網絡的技巧

- LSTM為什麼好訓練

- Initialize

- Regularization

- Optimizer

- Batch Normalization

2.seq2seq 講解&實作 

3.Attention model 

4.問卷調查



SELU

LeCun Normal\(權重平均0, 變異數1\)

輸入資料也要平均0, 變異數1





RNN Encoder - Decoder 架構



sequence to sequenct \(seq2seq\)

- Machine translation

- Text summarization

- Chatbot\(Conversation\)

- Reading Comprehension

- Speech to natural language

- Video Caption









